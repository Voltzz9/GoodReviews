---
title: "Goodreads Reviews Analysis"
author: "David Nicolay, Kellen Mossner, Matthew Holm"
date: "2024-10-01"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load libraries}
library(tidyverse)
library(tidytext)
library(stringr)
library(textdata)
library(lubridate)
library(ggplot2)
library(showtext)
library(ggridges)
library(wordcloud2)
library(plotly)
```

Setting up custom themes
```{r}
darjeeling1 <- c("#B22222", "#00A08A", "#F2AD00", "#F98400", "#5BBCD6")
axis_color <- "#2D2D2D"

# Set the font for plots
font_add_google("Montserrat") # Formal font
showtext_auto()

my_custom_theme <- theme_minimal() +
  theme(
    plot.background = element_rect(fill = "#f2e6c9", color = NA),
    panel.background = element_rect(fill = "#f2e6c9", color = NA),
    title = element_text(color = "#2D2D2D", size = 20, family = "Montserrat"),
    axis.text = element_text(color = "#2D2D2D", size = 12, family = "Montserrat"),
    axis.title = element_text(face = "bold", color = "#FF8500", size = 14, family = "Montserrat"),
    legend.background = element_rect(fill = "#f2e6c9", color = NA),
    legend.key = element_rect(fill = "#f2e6c9", color = NA),
    panel.grid.major = element_line(color = "#2D2D2D", linewidth = 0.2),  # black gridlines
    panel.grid.minor = element_line(color = "#2D2D2D", linewidth = 0.1),
    axis.title.x = element_text(margin = margin(t = 15)),  # Add spacing to the top of the x-axis title
    axis.title.y = element_text(margin = margin(r = 15))  # Add spacing to the right of the y-axis title
  )

# Set as default theme
theme_set(my_custom_theme)
```

## Import the data
```{r}
reviews <- read.csv("data/goodreads_reviews_all.csv", header = TRUE)
head(reviews)
```
## Data Preprocessing
```{r}
# Add Review.ID
reviews <- reviews %>%
  mutate(Review.ID = row_number()) %>%         # Add the Review.ID column
  select(Review.ID, everything())  

# Remove rows with missing values
reviews <- reviews %>%
  filter(!is.na(Review.Text))

# Remove duplicate reviews
reviews <- reviews %>%
  distinct(Book.Title, Link, Review.Date, Review.Text, Review.Stars, Review.Likes)

# Convert Review.Date to Date format
reviews$Review.Date <- as.Date(reviews$Review.Date, format = "%B %d, %Y")

# Remove all special characters and convert to lowercase
reviews$Review.Text <- reviews$Review.Text %>%
    str_replace_all("[^[:alnum:]\\s]", "") %>%   # Remove special characters
    str_replace_all("\\s+", " ") %>%            # Replace multiple spaces/newlines/tabs with a single space
    str_trim() %>%        # Trim leading and trailing whitespace
    tolower()             # Convert to lowercase
```

## Exploratory Data Analysis
```{r dist of review stars}
ggplot(reviews, aes(x = Review.Stars)) +
  geom_histogram(binwidth = 1, fill = darjeeling1[2], color = "black", alpha = 0.8) +  # Set fill and outline colors
  scale_x_continuous(breaks = 1:5) +  # Set x-axis breaks to 1-5
  labs(title = "Distribution of Review Stars", x = "Review Stars", y = "Frequency")
```
We can see that the distribution of review stars is left skewed towards higher ratings, with a peak at 5 stars. This is a common pattern in review data, where people are more likely to leave reviews when they have strong positive or negative feelings about a product.

Could just be we have more data from recent years book reviews.
```{r}
# Assuming the 'Review.Date' column is in Date format
reviews <- reviews %>%
  mutate(Year = format(Review.Date, "%Y"))  # Extract the year from the Review.Date

# Summarize the count of reviews by Year and Review.Stars
review_counts <- reviews %>%
  group_by(Year, Review.Stars) %>%
  summarise(Count = n(), .groups = 'drop')  # Count reviews for each year and star rating

# Create the animated histogram with Plotly
plot <- plot_ly(data = review_counts,
                x = ~Review.Stars,
                y = ~Count,
                frame = ~Year,  # Use Year as the frame for animation
                type = 'bar',   # Change to bar plot
                name = 'Review Stars',
                marker = list(color = darjeeling1, line = list(color = 'black', width = 1)),  # Set fill and outline colors
                alpha = 0.8) %>%
  layout(title = "Distribution of Review Stars by Year",
         xaxis = list(title = "Review Stars", tickvals = 1:5),  # Set x-axis ticks to 1-5
         yaxis = list(title = "Frequency"),
         barmode = 'overlay') %>%
  animation_opts(frame = 100, redraw = TRUE) %>%
  animation_slider(currentvalue = list(prefix = "Year: "))  # Add a slider for year

# Show the plot
plot
```


Taking a look at the distribution of review stars for the top and worst rated books.
```{r dist of stars for top 10 books}
# Calculate average ratings and get the top and worst book
top_and_worst_books <- reviews %>%
  group_by(Book.Title) %>%
  summarise(Average.Rating = mean(Review.Stars, na.rm = TRUE)) %>%
  arrange(Average.Rating) %>%
  slice(c(n(), 1))  # Select the top (last) and worst (first) book, reversing their order

# Filter reviews for the top and worst books
top_worst_reviews <- reviews %>%
  filter(Book.Title %in% top_and_worst_books$Book.Title)

# Create a ridgeline plot for the top and worst book
ggplot(top_worst_reviews, aes(x = Review.Stars, y = Book.Title, fill = Book.Title)) +
  geom_density_ridges(stat = "binline", bins = 5, alpha = 0.8,) +
  scale_fill_manual(values = darjeeling1[c(1, 2)]) +  # Use first two colors from darjeeling1 for fill
  labs(title = "Distribution of Review Stars for Top and Worst Books",
       x = "Review Stars",
       y = "Book Title") +
  theme(legend.position = "none") 
```

Wow shocking.
```{r wordcloud}
# Tokenize the review text into words
word_counts <- reviews %>%
  unnest_tokens(word, Review.Text) %>%  # Tokenize review text into words
  count(word, sort = TRUE) %>%          # Count occurrences of each word
  filter(!word %in% stop_words$word)    # Remove stop words

# Create a word cloud using wordcloud2
wordcloud2(data = word_counts, size = 1, minSize = 1, shape = 'circle')
```
```{r wordcloud w/o book}
# Tokenize the review text into words
word_counts <- reviews %>%
  unnest_tokens(word, Review.Text) %>%  # Tokenize review text into words
  count(word, sort = TRUE) %>%          # Count occurrences of each word
  filter(!word %in% stop_words$word) %>%   # Remove stop words
  filter(!word %in% 'book', !word %in% 'books')

# Create a word cloud using wordcloud2
wordcloud2(data = word_counts, size = 1, minSize = 1, shape = 'circle')
```

```{r}
ggplot(reviews, aes(x = reorder(Book.Title, Review.Stars), y = Review.Stars)) +
  geom_boxplot(fill = "#F98400") +
  coord_flip() +  # Flip for readability
  labs(title = "Box Plot of Ratings by Book Title", x = "Book Title", y = "Rating")

reviews %>%
  mutate(YearMonth = format(Review.Date, "%Y-%m")) %>%
  group_by(YearMonth) %>%
  summarise(Review_Count = n()) %>%
  ggplot(aes(x = YearMonth, y = Review_Count)) +
  geom_line(color = "#00A08A") +
  labs(title = "Number of Reviews Over Time", x = "Date", y = "Count of Reviews") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


## Sentiment Analysis
```{r lexicons}
get_sentiments("afinn") %>% head(10)
get_sentiments("bing") %>% head(10)
get_sentiments("nrc") %>% head(10)
```


```{r}
reviews_sentiment <- reviews %>%
  unnest_tokens(word, Review.Text) %>%
  inner_join(get_sentiments("afinn")) %>%
  group_by(Book.Title) %>%
  summarize(sentiment = sum(value)) %>%
  arrange(desc(sentiment))

# View the top 10 books by sentiment score
head(reviews_sentiment, 10)
```
```{r nrc emotions}
extended_palette <- colorRampPalette(darjeeling1)

# Tokenize the review text into words and calculate sentiment counts
sentiment_counts <- reviews %>%
  unnest_tokens(word, Review.Text) %>%          # Tokenize review text into words
  inner_join(get_sentiments("nrc"), by = "word") %>%      # Join with NRC lexicon
  count(sentiment) %>%                          # Count occurrences of each sentiment
  arrange(desc(n))

# Reorder sentiment factor levels by count
sentiment_counts$sentiment <- factor(sentiment_counts$sentiment, levels = sentiment_counts$sentiment)

# Get the number of unique sentiments
num_sentiments <- length(unique(sentiment_counts$sentiment))

ggplot(sentiment_counts, aes(x = sentiment, y = n, fill = sentiment)) +
  geom_bar(stat = "identity", width = 0.9) +
  labs(title = "Sentiment Count in Book Reviews", x = "Sentiment", y = "Count") +
  scale_fill_manual(values = extended_palette(num_sentiments)) +  # Extend the palette to match sentiments
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1)) + # Customize axis titles
  scale_y_continuous(labels = scales::comma) 
```


```{r bing sentiments}
bing_word_counts <- reviews %>%
  unnest_tokens(word, Review.Text) %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()

bing_word_counts %>%
  group_by(sentiment) %>%
  slice_max(n, n = 10) %>%
  ungroup() %>%
  ggplot(aes(n, reorder(word, n), fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(x = "Contribution to sentiment", y = NULL,title = "Top words contributing to sentiment") +
  scale_fill_manual(values = c("positive" = darjeeling1[5],   # Set a color for positive sentiment
                               "negative" = darjeeling1[1])) +  # Set a color for negative sentiment
  theme(strip.text = element_text(size = 14))
```

## [NLP] Question: Which review words resulted in highest rating?
First let's clean the dataset for our specific purpose. The words should also be tokenized and stopwords removed.

```{r tokenize}
replace_reg <- "(https?:.*?([\\s]|[a-zA-Z0-9]$))|(www:.*?([\\s]|[a-zA-Z0-9]$))"
unnest_reg <- "[^A-Za-z_\\d#@']"
# Select the relevant columns
words_rating_reviews <- reviews %>% 
  select(Review.Text, Review.Stars)
  
# Tokenize the review text
words_ratings <- words_rating_reviews %>%
  unnest_tokens(word, Review.Text, token = "regex", pattern = unnest_reg, drop = FALSE) %>%
  anti_join(stop_words) # Remove stop words
```

```{r calc_avg_rating}
# Calculate average ratings for each word
word_avg_ratings <- words_ratings %>%
  group_by(word) %>%
  summarise(
    avg_rating = mean(Review.Stars),
    count = n()
  ) %>%
  filter(count >= 10)  # Filter words that appear at least 10 times
```


Now let's find the top words by average rating.
```{r}
# Find the words with the highest ratings
top_words <- word_avg_ratings %>%
  arrange(desc(avg_rating)) %>%
  head(20)

# Display the results
print(top_words)
```
```{r}
# Find the words with the highest ratings
top_words <- word_avg_ratings %>%
  arrange(avg_rating) %>%
  head(20)

# Display the results
print(top_words)
```

As somewhat is to be expected, the common words that result in high reviews don't generalize well across books. No trend can easily be identified from this top average rating list.






## [Sentiment Analysis] Question: How does the sentiment of reviews correlate with the star rating given?

```{r}
# Calculate sentiment score for each review
sentiment_scores <- reviews %>%
  unnest_tokens(word, Review.Text) %>%
  inner_join(get_sentiments("afinn")) %>%
  group_by(Book.Title, Link, Review.Date, Review.Stars, Review.Likes) %>%
  summarize(sentiment_score = sum(value), .groups = 'drop')

# Calculate correlation
correlation <- cor(sentiment_scores$Review.Stars, sentiment_scores$sentiment_score)

# Visualize relationship between sentiment score and star rating
ggplot(sentiment_scores, aes(x = sentiment_score, y = Review.Stars)) +
  geom_jitter(alpha = 0.1, color = darjeeling1[1]) +
  geom_smooth(method = "lm", se = FALSE, color = darjeeling1[2]) +
  labs(title = "Sentiment Score vs. Star Rating",
       x = "Sentiment Score",
       y = "Star Rating",
       subtitle = paste("Correlation:", round(correlation, 2))) +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))
```
```{r}
# Average sentiment score by star rating
avg_sentiment_by_stars <- sentiment_scores %>%
  group_by(Review.Stars) %>%
  summarize(avg_sentiment = mean(sentiment_score))

ggplot(avg_sentiment_by_stars, aes(x = Review.Stars, y = avg_sentiment)) +
  geom_col(fill = darjeeling1) +
  labs(title = "Average Sentiment Score by Star Rating",
       x = "Star Rating",
       y = "Average Sentiment Score") +
  theme(plot.title = element_text(hjust = 0.5))
```

```{r}
# Sentiment over time
sentiment_scores %>%
  ggplot(aes(x = Review.Date, y = sentiment_score)) +
  geom_smooth(method = "loess", se = FALSE, color = darjeeling1[4]) +
  labs(title = "Sentiment Score Trend Over Time",
       x = "Review Date",
       y = "Sentiment Score") +
  theme(plot.title = element_text(hjust = 0.5))
```

```{r avg sent per year bar}
avg_sentiment_per_year <- sentiment_scores %>%
  mutate(year = year(Review.Date)) %>%         # Extract the year from Review.Date
  group_by(year) %>%                           # Group by year
  summarize(avg_sentiment_score = mean(sentiment_score, na.rm = TRUE))  # Calculate average sentiment score

# Plot the average sentiment score per year as a histogram
ggplot(avg_sentiment_per_year, aes(x = year, y = avg_sentiment_score)) +
  geom_col(fill = darjeeling1[4]) +  # Use geom_col to create a histogram
  labs(title = "Average Sentiment Score per Year",
       x = "Year",
       y = "Average Sentiment Score") +
  theme(plot.title = element_text(hjust = 0.5))
```

```{r avg sent per year line} 
# Plot the average sentiment score per year
ggplot(avg_sentiment_per_year, aes(x = year, y = avg_sentiment_score)) +
  geom_line(color = darjeeling1[4], linewidth = 1) +
  labs(title = "Average Sentiment Score per Year",
       x = "Year",
       y = "Average Sentiment Score") +
  theme(plot.title = element_text(hjust = 0.5))
```

```{r avg stars per year}
# Calculate average stars per year
avg_stars_per_year <- reviews %>%
  mutate(year = year(Review.Date)) %>%         # Extract the year from Review.Date
  group_by(year) %>%                           # Group by year
  summarize(avg_stars = mean(Review.Stars, na.rm = TRUE))  # Calculate average stars per year

# Plot both bar plot and line plot for average stars per year
ggplot(avg_stars_per_year, aes(x = year, y = avg_stars)) +
  geom_col(fill = darjeeling1[1], alpha = 0.7) +  # Bar plot with fill color and some transparency
  geom_line(color = darjeeling1[4], size = 1.2) +  # Line plot with another color
  geom_point(color = darjeeling1[4], size = 2) +   # Add points for each year on the line plot
  labs(title = "Average Stars per Year",
       x = "Year",
       y = "Average Stars") +
  theme(plot.title = element_text(hjust = 0.5))
```


```{r}
# Correlation between sentiment score and likes
likes_correlation <- cor(sentiment_scores$sentiment_score, sentiment_scores$Review.Likes)

ggplot(sentiment_scores, aes(x = sentiment_score, y = Review.Likes)) +
  geom_point(alpha = 0.1, color = darjeeling1[5]) +
  geom_smooth(method = "lm", se = FALSE, color = darjeeling1[2]) +
  labs(title = "Sentiment Score vs. Review Likes",
       x = "Sentiment Score",
       y = "Number of Likes",
       subtitle = paste("Correlation:", round(likes_correlation, 2))) +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))
```

```{r}
unordered_books_sentiment <- sentiment_scores %>%
  group_by(Book.Title) %>%
  summarize(avg_sentiment = mean(sentiment_score),
            avg_stars = mean(Review.Stars),
            review_count = n())

print(unordered_books_sentiment)
```

## [Topic Analysis] Question: What are the most common topics or themes discussed in positive vs. negative reviews?
```{r}
# Assuming `reviews_df` contains the columns `Book.Title` and `Review.Text`
top_book_reviews <- unordered_books_sentiment %>%
  inner_join(reviews, by = "Book.Title") %>%
  select(Book.Title, Review.Text, Review.Stars, avg_sentiment) 

top_book_reviews <- top_book_reviews %>%
  mutate(review_type = case_when(
    Review.Stars >= 4 ~ "Positive",
    Review.Stars <= 2 ~ "Negative",
    TRUE ~ "Neutral"  # You can handle neutral reviews differently if desired
  ))

# Tokenize the review text
tokenized_reviews <- top_book_reviews %>%
  unnest_tokens(word, Review.Text)

# Remove stop words
data("stop_words")
tokenized_reviews <- tokenized_reviews %>%
  anti_join(stop_words, by = "word")

# Count the most frequent words in positive and negative reviews
word_count <- tokenized_reviews %>%
  filter(review_type != "Neutral") %>%
  group_by(review_type, word) %>%
  summarize(count = n()) %>%
  arrange(desc(count))

# Top words in positive reviews
top_positive_words <- word_count %>%
  filter(review_type == "Positive") %>%
  arrange(desc(count)) %>%
  head(50)

# Top words in negative reviews
top_negative_words <- word_count %>%
  filter(review_type == "Negative") %>%
  arrange(desc(count)) %>%
  head(50)

# View results
top_positive_words
top_negative_words

# View the result
# top_book_reviews
```
From this, we can see a lot of overlap (which makes sense in most cases since certain words are very likely to be used in book reviews in general - i.e. book, read, people, time). It would seem helpful to exclude these overlapping words when trying to distinguish unique themes or topics, but this would shrink the word counts (particularly for negative reviews) as shown below.

```{r}
# Step 1: Identify overlapping words
cleaned_word_count <- word_count %>%
  filter(str_detect(word, "^[a-zA-Z]+$"))  %>%   # Keep only English alphabetic words
  filter(!str_detect(word, "\\d"))  


overlap_words <- intersect(
  cleaned_word_count %>% filter(review_type == "Positive") %>% pull(word),
  cleaned_word_count %>% filter(review_type == "Negative") %>% pull(word)
)

# Step 2: Exclude overlapping words
filtered_word_count <- cleaned_word_count %>%
  filter(!word %in% overlap_words)

# Step 3: Get the top unique words for positive reviews
top_positive_unique_words <- filtered_word_count %>%
  filter(review_type == "Positive") %>%
  arrange(desc(count)) %>%
  head(50)
# Step 4: Get the top unique words for negative reviews
top_negative_unique_words <- filtered_word_count %>%
  filter(review_type == "Negative") %>%
  arrange(desc(count)) %>%
  head(50)

# View the results
top_positive_unique_words
top_negative_unique_words
```
Besides the names of authors/characters, words like:
- Eyeopening
- Enchanting
- Improvements
- Enthralling
stand out for positive reviews, while words like:
- Causation&Correlation
- Unoriginal
- Ableism
stand out for negative reviews. While this is definitely not an entirely accurate representation, it seems that positive reviews tend to discuss themes of charm, excitement and insightfulness. "Improvements" could very well refer to a series of books that were reviewed. Negative reviews discuss themes of unoriginality (which is a prevalent criticism among avid readers). Causation and Correlation is also referred to quite often - which could point to criticisms of plot and story lines. 




## Question: Can we detect sarcasm or irony in reviews, and how does it relate to the overall rating?

Sarcasm and irony are very challenging concepts to detect. A rudimentary way of tackling such an issue like this could be further sentiment analysis. This would entail analyzing negative reviews that contain positive sentiment.
```{r}
sentiment_scores <- top_book_reviews %>%
  unnest_tokens(word, Review.Text) %>%            # Tokenize the review text
  inner_join(get_sentiments("bing"), by = "word") %>%  # Join with sentiment lexicon
  count(Book.Title, Review.Stars, sentiment) %>%  # Count occurrences of positive/negative words
  spread(sentiment, n, fill = 0) %>%               # Spread sentiment into separate columns
  mutate(sentiment_score = positive - negative)     # Calculate sentiment score
# View sentiment scores
print(sentiment_scores)
```

From here, we can plot which books have the greatest sentiment score for reviews with less than 3 stars - which could direct us to reviews that have sarcasm/irony.


```{r}
sarcastic_books <- sentiment_scores %>%
  filter(Review.Stars < 3, sentiment_score > 0) 

# Print the resulting books
print(sarcastic_books)

# Step 2: Limit to top 10 books by sentiment score
top_n_books <- sarcastic_books %>%
  arrange(desc(sentiment_score)) %>%
  head(10)  # Change this number to show more or fewer books

# Print the resulting top books
print(top_n_books)

# Step 3: Create a plot for the top books
ggplot(top_n_books, aes(x = reorder(Book.Title, -sentiment_score), y = sentiment_score)) +
  geom_col(fill = "skyblue") +
  labs(title = "Top 10 Books with Less Than 3 Stars and Positive Sentiment",
       x = "Book Title",
       y = "Sentiment Score") +
  coord_flip() +  # Flip the axes for better readability
  theme_minimal()
```
For these books to have 1 or 2 star reviews with such high sentiment scores definitely indicate that there is probably some form of expression where the intended meaning differs from the literal meaning of the words used.
After seeing these results, all that is left is to read the reviews ourselves to gauge whether or not these reviews contain verbal irony.

```{r}

average_ratings <- reviews %>%
  group_by(Book.Title) %>%
  summarize(avg_rating = mean(Review.Stars))  # Use na.rm to handle any NA values

print(average_ratings)

# Filter for sarcastic reviews
sarcastic_reviews <- sentiment_scores %>%
  filter(sentiment_score > 0, Review.Stars <= 2) 

# Create a sarcasm indicator in the sarcastic_reviews dataframe
sarcastic_reviews <- sarcastic_reviews %>%
  mutate(sarcasm = 1)  # Mark sarcastic reviews

# Create a non-sarcastic data frame for comparison
non_sarcastic_reviews <- sentiment_scores %>%
  filter(!(sentiment_score > 0 & Review.Stars <= 2)) %>%  # Exclude sarcastic reviews
  mutate(sarcasm = 0)  # Mark non-sarcastic reviews

# Combine both data frames
combined_reviews <- bind_rows(sarcastic_reviews, non_sarcastic_reviews)

# Merge with average ratings to include average book rating
final_analysis <- combined_reviews %>%
  group_by(Book.Title) %>%
  summarize(avg_rating = mean(Review.Stars, na.rm = TRUE), 
            sentiment_score = mean(sentiment_score, na.rm = TRUE),
            sarcasm = first(sarcasm))  # Use first(sarcasm) to get sarcasm indicator
# Calculate correlation between sentiment score and average rating
correlation_result <- cor(final_analysis$sentiment_score, final_analysis$avg_rating)
print(paste("Correlation between sentiment score and average book rating:", correlation_result))

# Run a linear regression analysis
model <- lm(avg_rating ~ sentiment_score + sarcasm, data = final_analysis)
summary(model)

library(ggplot2)

# Create a scatter plot
ggplot(final_analysis, aes(x = sentiment_score, y = avg_rating, color = factor(sarcasm))) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Sentiment Score vs. Average Book Rating",
       x = "Sentiment Score",
       y = "Average Book Rating",
       color = "Sarcasm Indicator") +
  theme_minimal()


```
Based on what we see above, we note that:
- Reviews marked as sarcastic tend to lower the average ratings despite having potentially positive sentiment
- The p-value for the sarcasm coefficient is very low (4.32e-09), indicating that the effect of sarcasm on average book ratings is statistically significant. It's also important to note the very low R-squared value though, indicating other factors play a more substantial role in influencing book ratings.
-Reviews that contain sarcastic remarks may mislead potential readers into thinking a book is being praised, when in reality, it is being criticized. This disconnect can lead to lower ratings as readers might find that the book does not meet their expectations.

In conclusion, it is fair to say that there MIGHT be some evidence of sarcastic reviews having an impact on the overall rating, but it is more likely that other variables a more important in predicting overall review scores.
