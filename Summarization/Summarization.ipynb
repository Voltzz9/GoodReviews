{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16bab3fc-d83f-40fd-8ca4-8590f72b3114",
   "metadata": {},
   "source": [
    "# Data Science 346 Project Stellenbosch University\n",
    "### Team:\n",
    "- David Nicolay\n",
    "- Kellen Mossner\n",
    "- Matthew Holm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8157126f-431f-448c-94bb-4b8464043d6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2841632809.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[124], line 13\u001b[1;36m\u001b[0m\n\u001b[1;33m    impozrt re\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from langdetect import detect, DetectorFactory\n",
    "impozrt re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# Set Random seed for reproducible results\n",
    "random_seed = 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "06525152-c482-4311-aa23-f2b53204eba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional Libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caea788-fb05-4751-87eb-22194b033b23",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6281542c-d91f-41d8-83e9-93a9156093f7",
   "metadata": {},
   "source": [
    "Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2703d11d-77df-4cac-be67-7281b193669b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Title</th>\n",
       "      <th>Link</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Review Date</th>\n",
       "      <th>Review Stars</th>\n",
       "      <th>Review Likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ways of Seeing</td>\n",
       "      <td>https://www.goodreads.com/book/show/2784.Ways_...</td>\n",
       "      <td>This book is based on a television series whic...</td>\n",
       "      <td>September 29, 2014</td>\n",
       "      <td>5</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ways of Seeing</td>\n",
       "      <td>https://www.goodreads.com/book/show/2784.Ways_...</td>\n",
       "      <td>I am not the audience for this book, mainly be...</td>\n",
       "      <td>June 3, 2014</td>\n",
       "      <td>3</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ways of Seeing</td>\n",
       "      <td>https://www.goodreads.com/book/show/2784.Ways_...</td>\n",
       "      <td>Way of Seeing, John Berger Ways of Seeing is a...</td>\n",
       "      <td>October 21, 2021</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ways of Seeing</td>\n",
       "      <td>https://www.goodreads.com/book/show/2784.Ways_...</td>\n",
       "      <td>First of all, this entire book is set in bold....</td>\n",
       "      <td>May 25, 2008</td>\n",
       "      <td>4</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ways of Seeing</td>\n",
       "      <td>https://www.goodreads.com/book/show/2784.Ways_...</td>\n",
       "      <td>This was a great introduction to the work of J...</td>\n",
       "      <td>March 12, 2020</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Book Title                                               Link  \\\n",
       "0  Ways of Seeing  https://www.goodreads.com/book/show/2784.Ways_...   \n",
       "1  Ways of Seeing  https://www.goodreads.com/book/show/2784.Ways_...   \n",
       "2  Ways of Seeing  https://www.goodreads.com/book/show/2784.Ways_...   \n",
       "3  Ways of Seeing  https://www.goodreads.com/book/show/2784.Ways_...   \n",
       "4  Ways of Seeing  https://www.goodreads.com/book/show/2784.Ways_...   \n",
       "\n",
       "                                         Review Text         Review Date  \\\n",
       "0  This book is based on a television series whic...  September 29, 2014   \n",
       "1  I am not the audience for this book, mainly be...        June 3, 2014   \n",
       "2  Way of Seeing, John Berger Ways of Seeing is a...    October 21, 2021   \n",
       "3  First of all, this entire book is set in bold....        May 25, 2008   \n",
       "4  This was a great introduction to the work of J...      March 12, 2020   \n",
       "\n",
       "   Review Stars  Review Likes  \n",
       "0             5           513  \n",
       "1             3           216  \n",
       "2             4             0  \n",
       "3             4           106  \n",
       "4             4            80  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Data\n",
    "reviews = pd.read_csv(\"../WebScrapingExplore/data/goodreads_reviews_all.csv\")\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e4d9244-2fe3-4501-8941-9e2d77736ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29519 entries, 0 to 29518\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Book Title    29519 non-null  object\n",
      " 1   Link          29519 non-null  object\n",
      " 2   Review Text   29247 non-null  object\n",
      " 3   Review Date   29519 non-null  object\n",
      " 4   Review Stars  29519 non-null  int64 \n",
      " 5   Review Likes  29519 non-null  int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bb9d81-b081-4986-bcd9-a7a06bf58b86",
   "metadata": {},
   "source": [
    "Through investiagting our database further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0884873-89a2-40dc-bfc4-0372e2c0a02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect language\n",
    "def is_english(review):\n",
    "    try:\n",
    "        return detect(review) == 'en'\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0154a7e1-b5dd-47d8-be52-65d8a7316a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only English reviews- This may take a while\n",
    "reviews = reviews[reviews['Review Text'].apply(is_english)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f40c0b5-8259-47bc-8f9c-7cdf4f57368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the review text\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):  # Check if the input is not a string\n",
    "        text = str(text)  # Convert to string if it's not already\n",
    "    \n",
    "    text = re.sub(r'\\d+', '', text)  # Remove digits\n",
    "    text = text.lower()  # Lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = text.strip()  # Remove leading/trailing spaces\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20563400-20b0-4769-beb1-6d24ec084224",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_reviews = reviews.copy()\n",
    "processed_reviews['Review Text'] = reviews['Review Text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d3d7e29-5f5c-4e68-a437-028712a89b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        this book is based on a television series whic...\n",
       "1        i am not the audience for this book mainly bec...\n",
       "2        way of seeing john berger ways of seeing is a ...\n",
       "3        first of all this entire book is set in bold i...\n",
       "4        this was a great introduction to the work of j...\n",
       "                               ...                        \n",
       "29514    i first discovered this book when i was  and i...\n",
       "29515    as per usual i loved it though i feel like the...\n",
       "29516    this was actually the book that made a reader ...\n",
       "29517    charlotte really put her whole brontussy into ...\n",
       "29518    jane eyre was orphaned and left in the care of...\n",
       "Name: Review Text, Length: 29519, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96744062-e67c-4ecd-b12d-e2c62d3a2ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92630c16-ffb5-47ee-8263-d366d0a4607f",
   "metadata": {},
   "source": [
    "# Part 1: Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f01b48e-9643-47bc-adde-ed87e63ef940",
   "metadata": {},
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f9c880-0873-41fe-b259-8df4176ab9be",
   "metadata": {},
   "source": [
    "Initializing the pipeline will take a while to run at first, since this function downloads the model weights (about 1.6gb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fbd3b63-8eeb-4846-a70b-6e29e4dab7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebbad676-5114-4c67-9fb7-147d0a612722",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davidnicolay/.local/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\", model=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cf2f02-1f0c-4c0b-b779-528fb3497d0d",
   "metadata": {},
   "source": [
    "Due to restricted input length of the summarizer the reviews text needs to be divided into chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62176a75-3abc-4304-adc1-55410253691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, max_chunk_size=500):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_size = 0\n",
    "    for word in words:\n",
    "        if current_size + len(word) > max_chunk_size:\n",
    "            chunks.append(' '.join(current_chunk))\n",
    "            current_chunk = [word]\n",
    "            current_size = len(word)\n",
    "        else:\n",
    "            current_chunk.append(word)\n",
    "            current_size += len(word) + 1  # +1 for space\n",
    "    if current_chunk:\n",
    "        chunks.append(' '.join(current_chunk))\n",
    "    return chunks\n",
    "\n",
    "def summarize_text(text, max_summary_length=150):\n",
    "    chunks = chunk_text(text)\n",
    "    summaries = []\n",
    "    for chunk in chunks:\n",
    "        summary = summarizer(chunk, max_length=max_summary_length, min_length=10)[0]['summary_text']\n",
    "        summaries.append(summary)\n",
    "    \n",
    "    final_summary = ' '.join(summaries)\n",
    "    if len(final_summary) > max_summary_length:\n",
    "        final_summary = summarizer(final_summary, max_length=max_summary_length, min_length=30)[0]['summary_text']\n",
    "    return final_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a6df7e-0359-45a4-9b50-40ff115e4650",
   "metadata": {},
   "source": [
    "Begin by summarizing 1 book's reviews - \"Ways of Seeing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "efa5dea0-cc95-4978-8eb2-94fec0ec8ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO change model to be able to handle longer length summarize inputs \n",
    "\n",
    "#book_title = \"Ways of Seeing\"\n",
    "# book_df = reviews[reviews['Book Title'] == book_title]\n",
    "\n",
    "# # Concatenate all reviews for the book\n",
    "# all_reviews = ' '.join(book_df['Review Text'].dropna())\n",
    "\n",
    "# # Generate a summary of the concatenated reviews\n",
    "# try:\n",
    "#     summary = summarize_text(all_reviews)\n",
    "# except Exception as e:\n",
    "#     print(f\"An error occurred: {e}\")\n",
    "#     summary = \"Error generating summary\"\n",
    "\n",
    "# # Calculate average rating\n",
    "# avg_rating = book_df['Review Stars'].mean()\n",
    "\n",
    "# # Create a new dataframe with the results\n",
    "# result_df = pd.DataFrame({\n",
    "#     'Book Title': [book_title],\n",
    "#     'Review Summary': [summary],\n",
    "#     'Average Rating': [avg_rating],\n",
    "#     'Number of Reviews': [len(book_df)]\n",
    "# })\n",
    "\n",
    "# # Display the results\n",
    "# print(result_df)\n",
    "\n",
    "# # Print some statistics\n",
    "# print(f\"\\nTotal length of all reviews: {len(all_reviews)} characters\")\n",
    "# print(f\"Length of summary: {len(summary)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695728bb-f0a5-475c-b976-ebf89601a819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba206aa4-bb28-4c99-9aa5-668b6f98e2ca",
   "metadata": {},
   "source": [
    "Here we can have a look at how the model does a good job of summarizing (but it essentially picks important sentences), however we still need to present it in a format that explains the overall sentiment from the readers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43c2f252-4952-477d-8184-ea5ec09ca297",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_test = summarizer(book_df.loc[3]['Review Text'], max_length=50, min_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19feaaa1-c1b0-4ce8-a7ef-459ae795c11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': '4 essays and 3 pictorial essays. It seems like museums are doing a lot of things wrong as well as right. Chapter on oil-painting was particularly interesting but it was the last one about advertising (or \"publicity\"'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6de8201a-f1e9-4586-af53-211c09f377c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First of all, this entire book is set in bold. I don\\'t know what crazy crazyman let that through the gate at Penguin but I just felt I had to point it out right away. It\\'s still worth reading. 4 essays and 3 pictorial essays. Really interesting stuff cutting away some of the bullshit associated with our appreciation of art. It seems like museums are doing a lot of things wrong as well as right. Chapter on oil-painting was particularly interesting but it was the last one about advertising (or \"publicity\" as it\\'s exclusively referred to in this book) that has me thinking. Advertising not only needs you to want this shirt, this car, the entire industry must endeavor to narrow the scope of your desires to make you amenable to the culture. The mindset must always be a future, better you achieved through important purchases. The essay is horrifying enough until you realise that it\\'s thirty years old, and this is now only one facet of a business that\\'s grown much more insidious. The ads shown are almost quaint in their straight sell.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_df.loc[3]['Review Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc71208-cf6e-4d30-bee8-bcf1f8036d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88e2133-dc63-4292-856b-cc4149e35ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6d203d-6da9-4ba0-bbd4-0260e08f8c21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efeb0cbf-70c2-4b49-815a-870eb2429542",
   "metadata": {},
   "source": [
    "## Encoder-Decoder Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7acb5a5a-8269-4371-8828-1426f069a24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8eb12e3b-d37c-434f-a750-590ac14f3ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ***************************************************************************\n",
    "\n",
    "\n",
    "def preprocess(reviews):\n",
    "    \"\"\"\n",
    "    Performs preprocessing operations such as removing new line characters.\n",
    "    \"\"\"\n",
    "    n_reviews = len(reviews)\n",
    "    print(f\"Number of reviews: {n_reviews}\")\n",
    "    for i in range(n_reviews):\n",
    "        review = reviews[i]\n",
    "        # Replace newlines with spaces\n",
    "        reviews[i] = review.replace('\\n', ' ').strip()\n",
    "        \n",
    "        \n",
    "def split_sentences(reviews):\n",
    "    \"\"\"\n",
    "    Splits the reviews into individual sentences.\n",
    "    \"\"\"\n",
    "    n_reviews = len(reviews)\n",
    "    for i in range(n_reviews):\n",
    "        review = reviews[i]\n",
    "        import nltk\n",
    "        nltk.download('punkt')\n",
    "        sentences = sent_tokenize(review)  # Tokenize into sentences\n",
    "        # Remove empty sentences and strip spaces\n",
    "        sentences = [sent.strip() for sent in sentences if sent.strip()]\n",
    "        reviews[i] = sentences\n",
    "        \n",
    "        \n",
    "def encode_sentences(reviews):\n",
    "    \"\"\"\n",
    "    Obtains sentence embeddings for each sentence in the reviews\n",
    "    using Sentence-BERT from the sentence-transformers library.\n",
    "    \"\"\"\n",
    "    enc_reviews = [None] * len(reviews)\n",
    "    cum_sum_sentences = [0]\n",
    "    sent_count = 0\n",
    "    \n",
    "    # Flatten reviews into a list of sentences\n",
    "    for review in reviews:\n",
    "        sent_count += len(review)\n",
    "        cum_sum_sentences.append(sent_count)\n",
    "\n",
    "    all_sentences = [sent for review in reviews for sent in review]\n",
    "    print('Loading pre-trained Sentence-BERT model...')\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    print('Encoding sentences...')\n",
    "    enc_sentences = model.encode(all_sentences, show_progress_bar=True)\n",
    "\n",
    "    # Group back encoded sentences by reviews\n",
    "    for i in range(len(reviews)):\n",
    "        begin = cum_sum_sentences[i]\n",
    "        end = cum_sum_sentences[i+1]\n",
    "        enc_reviews[i] = enc_sentences[begin:end]\n",
    "        \n",
    "    return enc_reviews\n",
    "        \n",
    "    \n",
    "def summarize(reviews):\n",
    "    \"\"\"\n",
    "    Performs summarization of book reviews.\n",
    "    \"\"\"\n",
    "    n_reviews = len(reviews)\n",
    "    summary = [None] * n_reviews\n",
    "    print('Preprocessing...')\n",
    "    preprocess(reviews)\n",
    "    \n",
    "    print('Splitting into sentences...')\n",
    "    split_sentences(reviews)\n",
    "    \n",
    "    print('Starting to encode...')\n",
    "    enc_reviews = encode_sentences(reviews)\n",
    "    print('Encoding Finished')\n",
    "    \n",
    "    for i in range(n_reviews):\n",
    "        enc_review = enc_reviews[i]\n",
    "        n_clusters = int(np.ceil(len(enc_review) ** 0.5))  # Number of clusters\n",
    "        \n",
    "        # Perform KMeans clustering\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "        kmeans = kmeans.fit(enc_review)\n",
    "        \n",
    "        avg = []\n",
    "        closest = []\n",
    "        for j in range(n_clusters):\n",
    "            idx = np.where(kmeans.labels_ == j)[0]\n",
    "            avg.append(np.mean(idx))\n",
    "        closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, enc_review)\n",
    "        \n",
    "        # Ordering sentences by clusters\n",
    "        ordering = sorted(range(n_clusters), key=lambda k: avg[k])\n",
    "        summary[i] = ' '.join([reviews[i][closest[idx]] for idx in ordering])\n",
    "    \n",
    "    print('Clustering Finished')\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab984d2a-8178-4f5a-92da-f0a4b3fc6a0a",
   "metadata": {},
   "source": [
    "#### What is happening here?\n",
    "Encoding:\n",
    "- Sentence-BERT: The function uses a pre-trained Sentence-BERT model ('all-MiniLM-L6-v2') to convert each sentence into a vector embedding. - This embedding is a numerical representation of the sentence that captures its semantic meaning.\n",
    "- It first flattens all the sentences from the reviews into a single list and then encodes them.\n",
    "- After encoding, it restructures the embeddings back into their original review groups.\n",
    "\n",
    "Clustering:\n",
    "- For each review, the number of clusters is determined using the square root of the number of sentences (rounded up).\n",
    "- KMeans clustering is performed on the sentence embeddings to group similar sentences.\n",
    "- For each cluster, **the sentences closest to the cluster center (based on the distance between sentence embeddings) are selected.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5a344d-e052-411e-b037-9b719a5b1e68",
   "metadata": {},
   "source": [
    "### Applying to a single book's review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2739a959-7643-41b1-9e23-2e21c952772f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_subset = reviews[reviews['Book Title'] == 'Ways of Seeing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c0363ed2-5433-4a0a-9d14-59d2ee3f7dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing...\n",
      "Number of reviews: 120\n",
      "Splitting into sentences...\n",
      "Starting to encode...\n",
      "Loading pre-trained Sentence-BERT model...\n",
      "Encoding sentences...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a890470376694f16a3ce1c931c48550a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Finished\n",
      "Clustering Finished\n"
     ]
    }
   ],
   "source": [
    "way_of_seeing_reviews = reviews_subset['Review Text'].tolist()\n",
    "summaries = summarize(way_of_seeing_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c19353f4-f1bd-424e-9468-9391ce4ad9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In general, the lesson of this book is that all art is bad for you, except the pieces that the authors of this book like. I am not the audience for this book, mainly because I've already read and more or less digested the handful of essays and ideas on which it is based. This is true. They don't discuss the 20th century at all (I know they know that twentieth century art exists; perhaps, as good Benjaminian Marxists, they don't like abstraction or difficulty). Holbein's 'Ambassadors' is read as an example of this; the incredible distorted skull in the painting is the exception which proves the rule of oil paintings rather than, you know, showing that oil paintings can be self-critical, as are most good artworks of any kind. Harmful because those who accept it will say silly things, and because those who read it and reject it out of hand (due to the rhetoric, bad arguments, or conceptual confusion) won't be challenged to, you know, care about other people.\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3928fac9-10b9-46fc-bc7b-98d18b378739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am not the audience for this book, mainly because I\\'ve already read and more or less digested the handful of essays and ideas on which it is based. The seven chapters break down fairly simply. 1: Benjamin\\'s \\'Work of Art\\'--the ability to reproduce images alters the way we encounter works of art. This seems reasonable. Nobody gets to see a Giotto without having seen a reproduction first, except someone who has no interest in the Giotto in the first place. But Berger et al* go a step further: we need to use the fact that we encounter works of art differently to undermine the ruling class\\'s privilege and the \"specialized experts who are the clerks of the nostalgia of a ruling class in decline.\" That\\'s on page 32. Part of me, a large part, laments the fact that you\\'d never get that published today, not even on a website. Another part of me laments the stupidity of intellectuals who put their faith in the inherent goodness of The People. The People does not have a good track record when it comes to art appreciation. That\\'s not to say that people can\\'t learn to appreciate art, only that We are no better and no worse than the ruling class was. We need to learn, we need to be taught, you can\\'t do that if you assume that We are inherently able to do the right thing. 2 & 3: Women are depicted differently from men, and, frankly, not in ways that are healthy for anyone, but particularly not for women. I agree. Which makes it breathtaking to see the authors get so many things wrong, either intentionally (cutting short the bible verse in which God punishes Eve *and Adam*); stupidly (non-Western art forms show women as active participants in sex, so that are isn\\'t morally dubious); or in ways that are, ahem, temporally bound (\"Hair is associated with sexual power, with passion.\" Seventies!). 5: Oil paintings are bourgeois and generally not morally okay. Holbein\\'s \\'Ambassadors\\' is read as an example of this; the incredible distorted skull in the painting is the exception which proves the rule of oil paintings rather than, you know, showing that oil paintings can be self-critical, as are most good artworks of any kind. In general, the lesson of this book is that all art is bad for you, except the pieces that the authors of this book like. They like pieces by artists who can plausibly be turned into radicals, because only radicals can be interesting (Franz Hals; William Blake). They don\\'t discuss the 20th century at all (I know they know that twentieth century art exists; perhaps, as good Benjaminian Marxists, they don\\'t like abstraction or difficulty). They\\'re also very uncomfortable with religious art, and want to group, e.g., Ambrosius Benson\\'s Mary Magdalene with the absurd and/or pornographic Magdalene of later times, rather than admitting the rather obvious differences (Benson\\'s is rich, but not, how can I put this... naked and disheveled.) Since the authors have a hard time saying what they actually like (vs. what they suspect is oppressive), you get idiocies like this: Rembrandt\\'s famous late portrait shows a man for whom \"all has gone except a sense of the question of existence, of existence as a question.\" A little thought would show that this is the sort of conservative pablum Great Artists have been serving up for generations. 6 & 7: Advertizing uses art to make you think you want things you don\\'t want and that you can get them, so you don\\'t need to think about what you really want, e.g., more time away from the office. This is true. In sum: I was sucked in by the idea that this was a book about understanding art. It is not. It is critical theory for high-school readers. Good for what it is, but extremely narrow in scope, and quite harmful for anyone who swallows it whole rather than taking a few minutes to worry away at its assumptions. Harmful because those who accept it will say silly things, and because those who read it and reject it out of hand (due to the rhetoric, bad arguments, or conceptual confusion) won\\'t be challenged to, you know, care about other people. * Humorous aspect of this book: it makes a big deal about how it was written by a group of people, because, you know, individuals are bad, and groups are good. You\\'ll note that the book is sold as a book by John Berger. You can draw the conclusion.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['Review Text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3251ebcd-af82-443c-89e9-21d9463d85ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d085d8-14e2-418f-8c71-d1234c974ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cad6b32-13dd-436d-8f3a-1d794598df15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89077758-4c9a-4dbe-b8ab-2444e4602267",
   "metadata": {},
   "source": [
    "## Same Approach as in class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b79e2cc-6b26-483b-bc1b-ec67e30d0191",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259b778a-c6b7-4cbc-b5d6-a42cd1a8d6c0",
   "metadata": {},
   "source": [
    "#### First Apply to 1 book for example sake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "47e1c323-0f0c-4537-adc4-6d4db27590f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"KMeans is known to have a memory leak on Windows with MKL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b8c2c6f4-62c7-49e0-a007-ded060e261a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing...\n",
      "Number of reviews: 120\n",
      "Splitting into sentences...\n",
      "Starting to encode...\n",
      "Loading pre-trained Sentence-BERT model...\n",
      "Encoding sentences...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f30ba20e8d5f4d77a04f800ea94e1d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Finished\n",
      "Clustering Finished\n"
     ]
    }
   ],
   "source": [
    "born_a_crime_subset = reviews[reviews['Book Title'] == 'Born a Crime: Stories From a South African Childhood']\n",
    "born_a_crime_reviews = born_a_crime_subset['Review Text'].tolist()\n",
    "born_a_crime_summaries = summarize(born_a_crime_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "be1f3afc-c7af-4773-b48b-d4d3b63401d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Noah sums it up very well: in America we had 1) forced removal of the native population to reservations, 2) slavery, followed by 3) segregation. Like in the best books, you learn some important history in the telling of his young life's story. One of the many things I didn't know about South Africa is that as most countries were trying to fix racist policies after the World War 2 holocaust had shown us where discrimination could lead, the South Africans or Afrikaners (as the Dutch colonists called themselves) were running towards institutionalized racism. This man's talent knows no ceiling.\""
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "born_a_crime_summaries[45]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b960995d-e9d6-4593-b3e4-f50d9997c731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"One of the best memoirs I've ever read, Born a Crime is so funny and wise and sad and reveals much about the writer.\",\n",
       " \"Trevor Noah is an exceptional young man raised by a strong, formidable mother who never gave up on him and loved him with a fierce pride.He never shrinks from complete honesty in the telling, even in those areas that don't reflect well on his teenaged and early adult self.\",\n",
       " 'One very amusing incident tells of how as a kid his rejection of going to the outside toilet in the rain led to a most unfortunate incident with his blind grandma.',\n",
       " \"Like in the best books, you learn some important history in the telling of his young life's story.\",\n",
       " 'Apartheid was made officially part of South African government in 1948; whereas, before you had casual, implied racism, now it was a system of specific laws that rated you as a person.',\n",
       " 'There were different rules for whites, colored (people descended from the first white settlers and the natives), blacks, Indians and Asians.',\n",
       " 'Blacks were at the bottom with prison time for those who produced children from a black and white union.',\n",
       " 'Hence the title, Born a Crime, is stating a fact of life in the nation of South Africa at that time.',\n",
       " \"One of the many things I didn't know about South Africa is that as most countries were trying to fix racist policies after the World War 2 holocaust had shown us where discrimination could lead, the South Africans or Afrikaners (as the Dutch colonists called themselves) were running towards institutionalized racism.\",\n",
       " 'The Afrikaners were fans of Hitler and actually formed a committee to study racism around the world and pick out the\"best\" bits for themselves.',\n",
       " 'They studied Australia, the Netherlands and the US.',\n",
       " 'Noah sums it up very well: in America we had 1) forced removal of the native population to reservations, 2) slavery, followed by 3) segregation.',\n",
       " 'In South Africa all 3 were done at the same time to the same people.',\n",
       " 'Noah is very wise to be so young, one of my favorite quotes from the book is \"The hood was strangely comforting, but comfort can be dangerous.',\n",
       " 'Comfort provides a floor but also a ceiling.\"',\n",
       " \"This man's talent knows no ceiling.\"]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "born_a_crime_reviews[45]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006a6b93-2b67-4841-a290-fca9cece6188",
   "metadata": {},
   "source": [
    "So far so good - the summaries skip over some information here and there, but at a glance, they look quite accurate. Now let's take it a step further and generate a final summary that should encapsulate the core themes and ideas mentioned in the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ef5ac854-854a-4031-a317-a3bd7144e330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_final(all_summaries):\n",
    "    \"\"\"\n",
    "    Performs summarization of the combined summaries.\n",
    "    \"\"\"\n",
    "    all_summaries = [summary.replace('\\n', ' ').strip() for summary in all_summaries]\n",
    "    \n",
    "    from nltk.tokenize import sent_tokenize\n",
    "    all_sentences = []\n",
    "    for summary in all_summaries:\n",
    "        sentences = sent_tokenize(summary)\n",
    "        sentences = [sent.strip() for sent in sentences if sent.strip()]\n",
    "        all_sentences.extend(sentences)\n",
    "    \n",
    "    print('Loading pre-trained Sentence-BERT model...')\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    print('Encoding sentences...')\n",
    "    enc_sentences = model.encode(all_sentences, show_progress_bar=True)\n",
    "\n",
    "    n_clusters = int(np.ceil(len(enc_sentences) ** 0.5))\n",
    "    print('Clustering sentences...')\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    kmeans = kmeans.fit(enc_sentences)\n",
    "    \n",
    "    avg = []\n",
    "    closest = []\n",
    "    for j in range(n_clusters):\n",
    "        idx = np.where(kmeans.labels_ == j)[0]\n",
    "        avg.append(np.mean(idx))\n",
    "    closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, enc_sentences)\n",
    "    \n",
    "    ordering = sorted(range(n_clusters), key=lambda k: avg[k])\n",
    "    final_summary = ' '.join([all_sentences[closest[idx]] for idx in ordering])\n",
    "    \n",
    "    print('Final summary generated')\n",
    "    return final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "dca68aef-92f3-4472-89a5-3b42eb75f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_book_description(summary):\n",
    "    \"\"\"\n",
    "    Takes the final summary of reviews and generates a book description.\n",
    "    \"\"\"\n",
    "    description_pipeline = pipeline(\"text2text-generation\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "    prompt = (\n",
    "        \"Convert the following summary into a structured book description that describes the book's content, \"\n",
    "        \"themes, and significance: \" + summary\n",
    "    )\n",
    "\n",
    "    result = description_pipeline(prompt, max_length=250, min_length=100, do_sample=False)\n",
    "\n",
    "    book_description = result[0]['generated_text']\n",
    "    #print(book_description)\n",
    "    return book_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2873e671-cec5-4b06-80f0-48c2867e0ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained Sentence-BERT model...\n",
      "Encoding sentences...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb30b948c96b4d148bee00d1fc9de6ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering sentences...\n",
      "Final summary generated\n"
     ]
    }
   ],
   "source": [
    "final_born_a_crime_summary = summarize_final(born_a_crime_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cdb17962-acfb-4ddd-8e8d-17d075a05ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"He was just Robert to Trevor, someone who was nice to him on Sundays and Christmas holidays, and on all those days when he was not giving in to hungry black women his Swiss, precious, and fair sperm. If you have a chance to listen to the book, instead of reading it, I recommend this experience highly. Noah's love and respect for his mother & the way she raised him shines through on nearly every page. Eye-opening and perspective changing in a way that's funny and deeply vulnerable, you'll feel educated and entertained at the same time. Trevor Noah is a remarkable person. I LOVED this book! I liked reading about his childhood. But Trevor Noah expertly maneuvers through different scenes--much of it due to his mixed background--and explains so much history with apartheid and the different tribes and the colored thing and life in the townships and life in the homeland and so on... South Africa does of course have it's problems, yet after this book one has to be at least more empathetic. . This sets the tone for a life full of bizarre moments due to race. For an enhanced experience, I highly recommend the audiobook version. Born a Crime is about growing up in South Africa: living under apartheid when his existence was evidence of a crime, life after apartheid, the deep bond between a mother and son, the unique challenges of growing up mixed race, and living with an abusive stepfather. I learned a lot about apartheid and I learned a lot about South Africa. I was so captivated by everything he said. So many of Trevor's stories revolved around his mother, and with good reason - she raised him alone (mostly), and so she was a huge influence on and guiding force of his life. Moved out of the house at the age of 17 because of his step-dad and was even jailed for using a fake license plate. I recommend this book to absolutely everyone, I got sooo much more than I expected from it. His relationship with his mother was a delight to read. reading this made me realize that i am grievously uneducated on apartheid. Imagine being born from a black mother and a white father in a country where interracial relationships were against the law. In the memoir, there are many things that I did not understand. It was fascinating learning about his life growing up as a mixed race child in pre- and post-Apartheid South Africa. I was instantly intrigued by his story, not only because of this unique perspective but also because he is such a wonderful storyteller.\""
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_born_a_crime_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f9e95f-8275-4ed7-85da-2135d4a7f06e",
   "metadata": {},
   "source": [
    "Ignoring the **extremely** odd first sentence, this final generated summary mentions essentially every aspect that you can find in most reviews (audiobook being better, Noah's relationship with his mother, the premise, etc). For the sake of coherency, we can now parse this final summary to `facebook/bart-large-cnn` with a prompt to reframe the summary as a book description.\n",
    "\n",
    "`facebook/bart-large-cnn` is a fine-tuned version of BART (Bidirectional and Auto-Regressive Transformer), a transformer-based sequence-to-sequence model introduced by Facebook AI, combining the advantages of bidirectional and auto-regressive models. The model uses an encoder-decoder architecture: the encoder processes the entire input (like BERT), and the decoder generates output token-by-token (like GPT).\n",
    "\n",
    "Pretrained on various denoising tasks to learn language patterns, BART was fine-tuned specifically on the CNN/DailyMail dataset to improve its summarization capabilities. During fine-tuning, the decoder attends to the encoder's output to generate contextually appropriate summaries (Attention Mechanisms). Beam search and length penalty were also used to avoid overly short summaries.\n",
    "\n",
    "The weights were initialized from the original BART model that was pretrained on a large corpus of text using the denoising autoencoding tasks mentioned earlier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "42560d2c-6553-4d1b-a2a3-c32329e09bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_description = generate_book_description(final_born_a_crime_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e5f30216-7aeb-4e4d-a1b6-ad65ea2d5af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Trevor Noah's love and respect for his mother & the way she raised him shines through on nearly every page. Eye-opening and perspective changing in a way that's funny and deeply vulnerable, you'll feel educated and entertained at the same time. For an enhanced experience, I highly recommend the audiobook version. Moved out of the house at the age of 17 because of his step-dad and was even jailed for using a fake license plate. Imagine being born from a black mother and a white father in a country where interracial relationships were against the law.\""
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718baf32-c6d4-4668-9da0-31ccf9114396",
   "metadata": {},
   "source": [
    "We can now apply this to any book we like to obtain an overview/description of the contents and themes soley based off of the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d7452c-9298-4786-9d15-46ad4c2e542d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c25d3b-5449-4a00-90ea-93db13b08ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37869bf5-9036-4074-b646-f99f0a0c01e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c87ff5c4-16d0-44db-9776-32baab367ad5",
   "metadata": {},
   "source": [
    "# Part 2: Manual Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8461ae-172c-4c6f-9be0-4550e3e35c53",
   "metadata": {},
   "source": [
    "## Star Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87dca2ba-3bc6-4474-ad56-756e004e41b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup target and predictor datasets\n",
    "X = reviews['Review Text'].values\n",
    "y = reviews['Review Stars'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cab88f-a862-4d3c-bb2a-99d4d99592be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=10000, stop_words='english')\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=random_seed)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Convert labels to categorical\n",
    "num_classes = len(np.unique(y_train))\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75daf232-eaf2-4b1f-8b12-c901fe69cc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4730 - loss: 1.2667 - val_accuracy: 0.5401 - val_loss: 1.0601\n",
      "Epoch 2/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6598 - loss: 0.8296 - val_accuracy: 0.5418 - val_loss: 1.1059\n",
      "Epoch 3/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8133 - loss: 0.5163 - val_accuracy: 0.5057 - val_loss: 1.3474\n",
      "Epoch 4/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9334 - loss: 0.2233 - val_accuracy: 0.5001 - val_loss: 1.9749\n",
      "Epoch 5/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9863 - loss: 0.0553 - val_accuracy: 0.5105 - val_loss: 2.6528\n",
      "Epoch 6/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9957 - loss: 0.0185 - val_accuracy: 0.4947 - val_loss: 3.1868\n",
      "Epoch 7/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9985 - loss: 0.0062 - val_accuracy: 0.4968 - val_loss: 3.4601\n",
      "Epoch 8/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9983 - loss: 0.0061 - val_accuracy: 0.5021 - val_loss: 3.6861\n",
      "Epoch 9/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9986 - loss: 0.0055 - val_accuracy: 0.4982 - val_loss: 3.9007\n",
      "Epoch 10/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0020 - val_accuracy: 0.5021 - val_loss: 4.0952\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Input(shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train.toarray(), y_train, epochs=10, batch_size=32, validation_split=0.3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dbde494c-a1f9-4ca8-8df2-a38f9fe5e0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.481\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test.toarray(), y_test, verbose=0)\n",
    "print(f'Test accuracy: {test_accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4355d99-9925-4f18-9dd7-b687ee5706e7",
   "metadata": {},
   "source": [
    "A test accuracy below 0.5 means we could have predicted 2.5 stars for every review and probably gotten beter results. The training accuracy seems to increase drastically however validation accuracy remains steady at around 0.51. This indicates overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01eb2fe7-6793-4cfc-8af3-ea8dfce652d7",
   "metadata": {},
   "source": [
    "TODO\n",
    "- metric graphs\n",
    "- improve model\n",
    "- look online for differnet approachs and things to do to improve\n",
    "- try gradient descent etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761eabc7-df37-4786-a739-4d85f2000063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adefceaf-23b4-4ea6-b226-71f0953be857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c8c973-439e-4890-8e56-373d13259c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66c642c-dc06-40b6-9f0d-edea4e3ba425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f80e861-6352-4cd8-ae09-fe6f36676fe2",
   "metadata": {},
   "source": [
    "### Example Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dc54f9-ee3b-409e-82c2-2c1704330955",
   "metadata": {},
   "source": [
    "Consider an example of a bad review. \"This book was absolutely terrible! How could you think this was a good idea.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82d55bf8-6ee0-4b07-bcb3-cc4db89a9714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Predicted rating: 1\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "sample_review = [\"This book was absolutely terrible! How could you think this was a good idea.\"]\n",
    "sample_review_tfidf = vectorizer.transform(sample_review)\n",
    "prediction = model.predict(sample_review_tfidf.toarray())\n",
    "predicted_rating = np.argmax(prediction) + 1\n",
    "print(f'Predicted rating: {predicted_rating}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cf4f2e-9ae0-4953-856e-07ac75750833",
   "metadata": {},
   "source": [
    "Consider an example of a long mixed review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2ec3016-8439-414d-a1e6-7d3083457bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Predicted rating: 3\n"
     ]
    }
   ],
   "source": [
    "sample_review = [\"I had high hopes for The Infinite Horizon after hearing so much about it. From the beginning, the premise seemed promising, and for the most part, it delivers on its intriguing concept. The plot revolves around a futuristic world where society grapples with the boundaries of artificial intelligence, humanity, and survival—concepts that have always fascinated me. The world-building is impressive, with detailed landscapes and a unique societal structure that keeps you hooked initially. The author has clearly put a lot of thought into constructing the futuristic world, and it shows in the vivid descriptions and creative technologies. However, while the world-building is rich, the characters left much to be desired. The protagonist, Lila, felt underdeveloped. I found myself frustrated at several points because her motivations were either unclear or inconsistent. In the beginning, she starts off as a strong, determined character, but midway through, her actions seem erratic and her growth stagnates. The dialogue, too, felt stilted at times, making it hard to connect with the characters emotionally. There were a few moments where I felt the conversations between key characters were forced, almost like they were inserted to explain plot points rather than feeling organic.On the flip side, I have to give credit where it’s due—the pacing of the story is solid for the most part. There are intense moments where you’re on the edge of your seat, particularly during the battle scenes. These scenes were written with such vivid detail that I could easily imagine them playing out in a movie. The action sequences are well thought out, and they definitely add excitement to the narrative. That being said, there were also moments where the pacing lagged, especially in the middle sections. Some chapters felt like filler, dragging on with unnecessary exposition and side plots that didn’t add much to the overarching story.\"]\n",
    "sample_review_tfidf = vectorizer.transform(sample_review)\n",
    "prediction = model.predict(sample_review_tfidf.toarray())\n",
    "predicted_rating = np.argmax(prediction) + 1\n",
    "print(f'Predicted rating: {predicted_rating}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4622fdb5-5172-42f7-992c-d100b8860460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47942b20-7c90-460e-82df-528f4e9d06c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a455b952-4e93-4212-9263-c1fc2f1c1b82",
   "metadata": {},
   "source": [
    "# Part 3: Category Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289681e2-c09a-4187-8df9-d62b219647b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
